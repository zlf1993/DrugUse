{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yanpe\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from CNN import get_cnn\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import csv\n",
    "import gensim\n",
    "\n",
    "K = 400 # word2vec embedding dimension\n",
    "L = 50 # 50 words limit for each sentence\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "_x = tf.placeholder(tf.float32, [None, L, K], name='input_x')\n",
    "_y = tf.placeholder(tf.float32, [None, NUM_CLASSES], name='input_y')\n",
    "\n",
    "predictions, loss, accuracy = get_cnn(_x, _y, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'dataset/word2vec_twitter_model.bin'\n",
    "#w2v_model = gensim.models.KeyedVectors.load_word2vec_format(MODEL_PATH, binary=True, limit=3000000)\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(MODEL_PATH, binary=True, limit=300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Och, the word \"420\" cannot be found in the w2v model!\n",
      "\n",
      "input shape:  (20, 50, 400)\n",
      "INFO:tensorflow:Restoring parameters from saved_model/model.ckpt\n",
      "\n",
      "RESULTS (+: positive; -: negative):\n",
      "+:  i enjoy smoking weed\n",
      "-:  the government should legalize crack and meth\n",
      "+:  snorting cocaine is a good time\n",
      "+:  smoke weed everyday\n",
      "-:  there is a man by the arcade selling sweetest dope\n",
      "-:  i should switch to crack and become the largest of the crack heads\n",
      "+:  smoking a blunt and keeping it real\n",
      "-:  420 blaze it with some sweet bud\n",
      "+:  the world would be better if we all smoked weed and did LSD\n",
      "-:  thinking about moving up to something more powerful perhaps crack or coke\n",
      "-:  i think all drugs should be illegal\n",
      "-:  the chimney is smoking and I mowed the grass\n",
      "-:  the opioid crisis has gotten out of control\n",
      "-:  my mom says cocaine and pills lead to failure\n",
      "-:  i have never done drugs especially not weed\n",
      "-:  special k is delicious\n",
      "-:  i feel like a complete dope\n",
      "-:  my bud and I are going to board on the sweet powder\n",
      "-:  the government should do something about all these drugs\n",
      "+:  people should in fact not smoke weed everyday\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "input_texts = [\n",
    "    'i enjoy smoking weed',\n",
    "    'the government should legalize crack and meth',\n",
    "    'snorting cocaine is a good time',\n",
    "    'smoke weed everyday',\n",
    "    'there is a man by the arcade selling sweetest dope',\n",
    "    'i should switch to crack and become the largest of the crack heads',\n",
    "    'smoking a blunt and keeping it real',\n",
    "    '420 blaze it with some sweet bud',\n",
    "    'the world would be better if we all smoked weed and did LSD',\n",
    "    'thinking about moving up to something more powerful perhaps crack or coke',\n",
    "    'i think all drugs should be illegal',\n",
    "    'the chimney is smoking and I mowed the grass',\n",
    "    'the opioid crisis has gotten out of control',\n",
    "    'my mom says cocaine and pills lead to failure',\n",
    "    'i have never done drugs especially not weed',\n",
    "    'special k is delicious',\n",
    "    'i feel like a complete dope',\n",
    "    'my bud and I are going to board on the sweet powder',\n",
    "    'the government should do something about all these drugs',\n",
    "    'people should in fact not smoke weed everyday'\n",
    "]\n",
    "#'''\n",
    "'''\n",
    "input_texts = [\n",
    "    'i enjoy BETA ALPHA',\n",
    "    'the government should legalize ALPHA and ALPHA',\n",
    "    'BETA ALPHA is a good time',\n",
    "    'BETA ALPHA everyday',\n",
    "    'there is a man by the arcade selling sweetest ALPHA',\n",
    "    'i should switch to ALPHA and become the largest of the ALPHA heads',\n",
    "    'BETA a ALPHA and keeping it real',\n",
    "    'ALPHA blaze it with some sweet ALPHA',\n",
    "    'the world would be better if we all BETA ALPHA and did ALPHA',\n",
    "    'thinking about moving up to something more powerful perhaps ALPHA or ALPHA',\n",
    "    'i think all ALPHA should be illegal',\n",
    "    'the chimney is BETA and I mowed the ALPHA',\n",
    "    'the ALPHA crisis has gotten out of control',\n",
    "    'my mom says ALPHA and ALPHA lead to failure',\n",
    "    'i have never done ALPHA especially not ALPHA',\n",
    "    'ALPHA is delicious',\n",
    "    'i feel like a complete ALPHA',\n",
    "    'my ALPHA and I are going to board on the sweet ALPHA',\n",
    "    'the government should do something about all these ALPHA',\n",
    "    'people should in fact not BETA ALPHA everyday'\n",
    "]\n",
    "'''\n",
    "x_ = []\n",
    "for tweet in input_texts:\n",
    "    tmp = []\n",
    "    for word in tweet.split(' '):\n",
    "        try:\n",
    "            tmp.append(w2v_model[word])\n",
    "        except:\n",
    "            print('Och, the word \\\"'+word+'\\\" cannot be found in the w2v model!')\n",
    "            ''' OOV word '''\n",
    "            tmp.append(np.random.uniform(-0.5,0.5,K)) # random vector range:(-0.5, 0.5)\n",
    "        if len(tmp) == L:\n",
    "            break # 50 words limit!!\n",
    "    while len(tmp) < L:\n",
    "        ''' pad with zero vectors if less than 50 words '''\n",
    "        tmp.append(np.zeros(K)) \n",
    "    x_.append(np.array(tmp))\n",
    "x_ = np.array(x_)\n",
    "\n",
    "print('\\ninput shape: ',x_.shape)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load parameters\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, 'saved_model/model.ckpt')\n",
    "\n",
    "    pred = sess.run([predictions], feed_dict={_x: x_})\n",
    "\n",
    "    pred = np.array(pred[0])\n",
    "    \n",
    "    ''' Display result '''\n",
    "    print('\\nRESULTS (+: positive; -: negative):')\n",
    "    for i in range(len(input_texts)):\n",
    "        if pred[i] == 1:\n",
    "            print('+: ',input_texts[i])\n",
    "        else:\n",
    "            print('-: ',input_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
